---
title: "Visualizing Text and Distributions"
output: 
html_document:
keep_md: true
toc: true
toc_float: true
 
---

# Data Visualization Project 03


In this exercise you will explore methods to visualize text data and practice how to recreate charts that show the distributions of a continuous variable. 


I decided to work on text mining techniques for Project 3.


## Part 2: Visualizing Text Data

Review the set of slides (and additional resources linked in it) for visualizing text data: https://www.reisanar.com/slides/text-viz#1

Choose any dataset with text data, and create at least one visualization with it. For example, you can create a frequency count of most used bigrams, a sentiment analysis of the text data, a network visualization of terms commonly used together, and/or a visualization of a topic modeling approach to the problem of identifying words/documents associated to different topics in the text data you decide to use. 

Make sure to include a copy of the dataset in the `data/` folder, and reference your sources if different from the ones listed below:

- [Billboard Top 100 Lyrics](https://github.com/reisanar/datasets/blob/master/BB_top100_2015.csv)

- [RateMyProfessors comments](https://github.com/reisanar/datasets/blob/master/rmp_wit_comments.csv)

- [FL Poly News 2020](https://github.com/reisanar/datasets/blob/master/poly_news_FL20.csv)

- [FL Poly News 2019](https://github.com/reisanar/datasets/blob/master/poly_news_FL19.csv)

(to get the "raw" data from any of the links listed above, simply click on the `raw` button of the GitHub page and copy the URL to be able to read it in your computer using the `read_csv()` function)


```{r}
library(tidyverse)
library(tidytext)
```




```{r}
getwd()
```



```{r}
# Reading in rate my professor data from Mendeley. This dataset is shared by Dr. Jibo HE, founder of the USEE Eye Tracking Inc.  and professor of Tsinghua University."https://data.mendeley.com/datasets/fvtfjyvw7d/2"

professor <- read_csv("C:/Users/Greg_Dills/Desktop/School/Data_Visualization/final_project_repo/dataviz_final_project/data/RateMyProfessor_Sample data.csv")

head(professor)
```
```{r}
# Better understanding the number of rows of data
nrow(professor)
```



```{r}
professor_df <- tibble(line = 1:18, text = professor$`comments`)
```



```{r}
tidy_professor <- professor_df %>%
                  unnest_tokens(word, text) %>%
    filter(!word %in% stop_words$word,str_detect(word, "[a-z]")) %>% 
                  anti_join(stop_words) %>% 
                  count(word, sort = TRUE)
```

```{r}
head(tidy_professor)
```



```{r}
library(wordcloud)
wordcloud(words = tidy_professor$word, freq = tidy_professor$n, max.words = 150, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
```

